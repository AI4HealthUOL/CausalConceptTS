{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c3388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from concept_discovery.kmeans import kmeans_explore, kmeans_predict, plot_concepts\n",
    "from imputer.load import load_imputer\n",
    "\n",
    "from utils.utils import compute_significance, plot_effects, get_global, get_channel_wise\n",
    "\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9c098",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d3b6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('data/x_train.npy')\n",
    "x_val = np.load('data/x_val.npy')\n",
    "x_test = np.load('data/x_test.npy')\n",
    "\n",
    "y_train = np.load('data/y_train.npy')\n",
    "y_val = np.load('data/y_val.npy')\n",
    "y_test = np.load('data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4533f",
   "metadata": {},
   "source": [
    "### Concepts loading or discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bff41",
   "metadata": {},
   "source": [
    "If you have already defined concepts, you should load here them as \n",
    "'train_concepts', 'val_concepts', and 'test_concets' and skip the next concept discovery step.\n",
    "Each of these should be of the shape (N_concepts, N_samples, Lengh, Channels) and should be binary masks. e.g. 0's where the concept is present, and 1's where don't. (as per diffusion model requierement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks=number of clusters to investigate, it will return a plot to make a final decision\n",
    "\n",
    "kmeans_explore(x_train,x_val,x_test,ks=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ff45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=desired number of concepts\n",
    "\n",
    "train_concepts,val_concepts,test_concepts = kmeans_predict(x_train,x_val,x_test,k=6)\n",
    "\n",
    "np.save('data/train_concepts.npy', train_concepts)\n",
    "np.save('data/val_concepts.npy', val_concepts)\n",
    "np.save('data/test_concepts.npy', test_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot your concepts\n",
    "\n",
    "max_lenght = x_test.shape[1] # length of the ts for plotting (can be smaller than the total)\n",
    "leadsn = [\"I\",\"II\",\"III\",\"aVR\",\"aVL\",\"aVF\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"] # name of your channels\n",
    "index = np.where(y_test==1)[0][0] # index of a class sample\n",
    "data = x_test # data to use (we used test for the index, so update accordly)\n",
    "concepts = test_concepts # concepts of the desired split (test again)\n",
    "save_fig = True \n",
    "savename = 'concepts.pdf'\n",
    "\n",
    "plot_concepts(max_length, leadsn, index, data, concepts, savefig=savefig, savename=savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cbc76b",
   "metadata": {},
   "source": [
    "### Classifier model loading or training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8b4ac",
   "metadata": {},
   "source": [
    "In this section, you can either load the model of your choice and assign it in a variable named 'classifier' or train an S4 model as in our main experiments paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ba628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you data should be in 'data/'\n",
    "\n",
    "# Construct the command to run the script\n",
    "command = [\n",
    "    'python', 'classifier/main.py',\n",
    "    '--input-size', max_length,\n",
    "    '--architecture', 's4',\n",
    "    '--precision', 32,\n",
    "    '--s4-n', 8,\n",
    "    '--s4-h', 512,\n",
    "    '--batch-size', 32,\n",
    "    '--epochs', 20,\n",
    "    '--input-channels', len(leadsn)\n",
    "]\n",
    "\n",
    "# it will save your model as first version (if there isn't any already)\n",
    "subprocess.run(command, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e53bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model configuration\n",
    "with open('version_0/hparams.yaml') as f:\n",
    "    hparams = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "namespace = Namespace(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and keep it in evaluation mode\n",
    "model = Main(hparams=namespace).cuda()\n",
    "model.load_weights_from_checkpoint('version_0/best_model.ckpt')\n",
    "classifier = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879bbd7b",
   "metadata": {},
   "source": [
    "### Diffusion model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create configuration files, one for each model\n",
    "\n",
    "config_paths = []\n",
    "\n",
    "for setting in ['class','norm']:\n",
    "\n",
    "    config = {\n",
    "        \"diffusion_config\": {\n",
    "            \"T\": 200,\n",
    "            \"beta_0\": 0.0001,\n",
    "            \"beta_T\": 0.02\n",
    "        },\n",
    "        \"wavenet_config\": {\n",
    "            \"in_channels\": len(leadsn), \n",
    "            \"out_channels\": len(leadsn),\n",
    "            \"num_res_layers\": 36,\n",
    "            \"res_channels\": 256, \n",
    "            \"skip_channels\": 256,\n",
    "            \"diffusion_step_embed_dim_in\": 128,\n",
    "            \"diffusion_step_embed_dim_mid\": 512,\n",
    "            \"diffusion_step_embed_dim_out\": 512,\n",
    "            \"s4_lmax\": x_train.shape[1],\n",
    "            \"s4_d_state\": 64,\n",
    "            \"s4_dropout\": 0.0,\n",
    "            \"s4_bidirectional\": 1,\n",
    "            \"s4_layernorm\": 1\n",
    "        },\n",
    "        \"train_config\": {\n",
    "            \"output_directory\": f\"/imputer/results/{setting}\",\n",
    "            \"ckpt_iter\": \"max\",\n",
    "            \"iters_per_logging\": 100,\n",
    "            \"n_iters\": 10000,\n",
    "            \"learning_rate\": 2e-4,   \n",
    "            \"target_class\": setting\n",
    "        },\n",
    "        \"trainset_config\": {\n",
    "            \"segment_length\": x_train.shape[1]\n",
    "        },\n",
    "        \"gen_config\": {\n",
    "            \"output_directory\": f\"/imputer/results/{setting}\",\n",
    "            \"ckpt_path\": f\"/imputer/results/{setting}/\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save the configuration to a JSON file\n",
    "    config_path = f'imputer/config_{setting}.json'\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    config_paths.append(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train each of the models\n",
    "\n",
    "for config_path in config_paths:\n",
    "    \n",
    "    command = [\n",
    "    'python', 'imputer/train.py',\n",
    "    '--config', config_path]\n",
    "\n",
    "    result = subprocess.run(command, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc5e7a",
   "metadata": {},
   "source": [
    "### Diffusion model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e40f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_path in config_paths:\n",
    "    \n",
    "    imputer = load_imputer(path_json=config_path,\n",
    "                           ckpt_iter=10000)\n",
    "    \n",
    "    target_class = 'class'                                    \n",
    "    target_generations = 40\n",
    "\n",
    "    for mask_s, mask in zip(['A','B','C','D','E','F'], [test_concetps[0],\n",
    "                                                             test_concepts[1],\n",
    "                                                             test_concepts[2],\n",
    "                                                             test_concepts[3],\n",
    "                                                             test_concepts[4],\n",
    "                                                             test_concepts[5]]):\n",
    "        for g in range(1,target_generations+1):\n",
    "            generation =  sampling(net,\n",
    "                                  (len(x_test), x_test.shape[1], x_test.shape[2]),                                    \n",
    "                                  diffusion_hyperparams, \n",
    "                                  cond = torch.from_numpy(samples).permute(0,2,1).cuda().float(),\n",
    "                                  mask = torch.from_numpy(mask).permute(0,2,1).cuda().float())                                            \n",
    "\n",
    "            outfile = f'{target_disease}_{mask_s}_{g}.npy'                  \n",
    "            new_out = os.path.join(ckpt_path, outfile)\n",
    "            np.save(new_out, generation.detach().cpu().numpy())\n",
    "            print(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce96dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40adc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6222a79",
   "metadata": {},
   "source": [
    "### Causal Concept Time Series Explainer (CusalConceptTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sig_dou_s, global_sig_doc_s = get_global(concepts=['A','B','C','D','E','F'], \n",
    "                                                target_generations=target_generations, \n",
    "                                                l_channels=x_test.shape[2])\n",
    "\n",
    "channel_sig_dou_s, channel_sig_doc_s = get_channel_wise(concepts=['A','B','C','D','E','F'],\n",
    "                                                        target_generations=target_generations, \n",
    "                                                        l_channels=x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694893f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_effects(global_sig_doc_g, \n",
    "         global_sig_doc_s, \n",
    "         global_do0_c, \n",
    "         channel_sig_doc_g, \n",
    "         channel_sig_doc_s, \n",
    "         channel_do0_c, \n",
    "         channels=leadsn,\n",
    "        concepts=['A','B','C','D','E','F'],\n",
    "         'do(causal).pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d9dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1b90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
